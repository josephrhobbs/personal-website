<!DOCTYPE html>
<html>

<head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-C43FKL8BR7"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-C43FKL8BR7');
</script>


<title>Convex Maneuver Planning | Joseph R. Hobbs</title>

<link rel="stylesheet" href="/style.css">

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=EB+Garamond:ital,wght@0,400..800;1,400..800&family=Outfit:wght@100..900&family=Fira+Code:wght@300..700&display=swap" rel="stylesheet">
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<link href="/prism.css" rel="stylesheet" />
<script src="/prism.js"></script>


<link rel="icon" type="image/x-icon" href="/media/favicon.ico">

</head>

<body>

<h1>Maneuver Planning</h1>

<div class="menu">

<a href="/">Home</a>

<a href="/about">About</a>

<a href="/projects">Projects</a>

<a href="/articles">Articles</a>

</div>



<div class="byline"><div>Joseph Hobbs</div><div>February 10, 2026</div></div>

<p>Recently, I've taken a great interest in the intersection of probability theory, optimization, and optimal control.  A recent paper by Z. Manchester's lab of MIT (formerly CMU), "Convex Maneuver Planning for Spacecraft Collision Avoidance" by F. Vega et al., found <a href="https://roboticexplorationlab.org/projects/cvx_cola.html">here</a>, caught my attention recently because it unifies optimal control and probability in the wonderfully fascinating (though incredibly harsh) environment of Earth orbit.  Here, I unpack the paper's main point by presenting a (highly) simplified example of the methodology presented.</p>

<h2>Review of Optimization</h2>

<p>For those unacquainted, the study of optimization formalizes "optimization problems" as <strong>optimization programs</strong>.  The field makes formal distinctions between various programs and provides rigorous, certifiable methods for solving them.  The most general optimization program is the <strong>Nonlinear Program</strong> (NLP).</p>

<p>\[ \begin{align*} P: \min_x f(x) & \\ \text{subject to } g_i(x) &\le 0 \\ h_j(x) &= 0 \end{align*} \]</p>

<p>Here, the optimization program \( P \) is general because we make <em>no assumptions</em> about the behavior of \( f \), \( g \), or \( h \).  These functions could be extraordinarily "nice" (linear functions, maybe!) or terribly behaved functions.  We call the vector \( x \) the <strong>decision variable</strong>, the scalar function \( f \) the <strong>objective</strong>, and the inequalities and equalities below the <strong>constraints</strong>.</p>

<p>Optimization programs, in general, can have three possible results: <strong>infeasibility</strong>, <strong>unboundedness</strong>, and <strong>optimality</strong>.  As you might imagine, we like that last one the best!  A program is <em>infeasible</em> if there exists no \( x \) that can satisfy the constraints.  For example, consider \( P_1 \).</p>

<p>\[ \begin{align*} P_1: \min_x x^2 & \\ \text{subject to } x &\ge 1 \\ x &\le -1 \end{align*} . \]</p>

<p>Clearly, because there is no such \( x \) such that \( x \ge 1 \) and \( x \le -1 \), this program is <em>infeasible</em>.  A problem is <em>unbounded</em> if there is a feasible region, but there is no optimal solution within it.  This is easily visualized by \( P_2 \).</p>

<p>\[ \begin{align*} P_2: \min_x 1/x & \\ \text{subject to } x &\ge 1 \end{align*} . \]</p>

<p>By increasing \( x \), we continually decrease the objective function, but we can never reach a minimum value, because we can just keep increasing \( x \) forever.  The program is feasible, but it is <em>unbounded</em>.  Finally, programs like \( P_3 \) can be solved to optimality.</p>

<p>\[ \begin{align*} P_3: \min_x x^2 & \\ \text{subject to } x &\le 1 \end{align*} . \]</p>

<p>Here, it's clear to see that \( x = 0 \) is the <em>minimizer</em> of \( P_3 \), and the program is solved to optimality.  Generally, the problem of solving NLPs is <strong>NP-hard</strong>.  I've presented a proof below, if you're interested.  Otherwise, you may safely skip ahead!</p>

<p>Hardness of NLP.  <strong>Theorem 1</strong>.  Let \( P \) be an NLP.  Then, solving \( P \) is NP-hard.</p>

<p>Hardness.  <strong>Definition 1</strong>.  A problem \( Q \) is <em>NP-hard</em> if, for every problem \( R \) in NP, there exists a polynomial-time reduction \( L \) such that \( L(R) \) rewrites \( R \) as \( Q \).</p>

<p>Hardness of SAT.  <strong>Lemma 1</strong>.  The problem of Boolean satisfiability (SAT) is NP-hard in the number of decision variables.  The problem of Boolean satisfiability is parameterized by decision variables \( x_i \) for \( i = 1, \cdots, N \) and an expression in conjunctive normal form (CNF), involving a finite number of terms joined by AND, where each term is a finite number of terms joined by OR.  For example, the following is CNF. </p>

<p>\[ ( x_1 \lor x_3 \lor x_7 ) \land ( x_2 \lor \neg x_1 ) \land \cdots \]</p>

<p>Polynomial-time reduction of SAT.  <strong>Lemma 2 and Proof</strong>.  SAT can be reduced to an NLP by introducing constraint</p>

<p>\[ x_i (1 - x_i) = 0 \]</p>

<p>for each \( x_i \) and introducing constraint</p>

<p>\[ \sum_{i = 1}^n x_i \ge 1 \]</p>

<p>for each CNF clause.  The first constraint enforces \( x_i \in \{ 0, 1 \} \), where \( 0 \) is falsy and \( 1 \) is truthy.  The second constraint ensures that each CNF clause is truthy; if at least one \( x_i \) in a clause is equal to one (truthy), the sum of \( x_i \) will be at least one and the entire clause will be truthy.  For clauses containing negatives like \( \neg x_1 \), we can replace \( x_i \) with \( 1 - x_i \) in the summation.  If all clauses are truthy, the entire CNF is truthy.  Here, we are only looking for feasible solutions, so we do not require any particular objective function.  The final NLP is</p>

<p>\[ \begin{align*} P_\mathrm{SAT}: \min_x 0 & \\ \text{subject to } x_i (1 - x_i) &= 0 \\ \sum_{i = 1}^n x_i &\ge 1 \end{align*} . \]</p>

<p>Note that we have abused notation to omit cases of negatives like \( \neg x_1 \).  In these cases, we modify the corresponding constraint as previously described.  With \( N \) decision variables, \( k \) CNF clauses, and a maximum of \( n \) decision variables per CNF clause, it is clear that <em>SAT can be reduced to NLP</em> in \( O(N + kn) \) time.</p>

<p>Hardness of NLP.  <strong>Proof of Theorem 1</strong>.  By Lemma 2, any SAT problem can be reduced to an NLP in \( O(N + kn) \) time.  Therefore, a polynomial-time reduction \( L_1 \) exists from SAT to NLP.  By Lemma 1, SAT is NP-hard, which means there exists a polynomial-time reduction \( L_2 \) exists from any problem in NP to SAT.  Therefore, the reduction \( L_3 := L_1(L_2(\cdot)) \) is polynomial-time.  This means that \( L_3 \) is a polynomial time reduction from any problem in NP to NLP.  By Definition 1, NLP is NP-hard \( \blacksquare \).</p>

<div class="notice">Under construction!</div>

</body>

</html>